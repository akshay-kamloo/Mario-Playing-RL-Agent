{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65b8146e",
      "metadata": {
        "id": "65b8146e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import deque\n",
        "import random, datetime, os, copy\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "from gym.wrappers import FrameStack\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a451f443",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a451f443",
        "outputId": "d35b9dbd-3580-4c6a-e862-106a510dc66c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gym-super-mario-bros==7.3.0"
      ],
      "metadata": {
        "id": "JG1tbM_yEGK9"
      },
      "id": "JG1tbM_yEGK9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traning the RL Agent"
      ],
      "metadata": {
        "id": "Z4GC9jPv4nS6"
      },
      "id": "Z4GC9jPv4nS6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ede00762",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ede00762",
        "outputId": "69ca02e6-bcf1-4384-b0ff-1feac660b4ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0,\n",
            "False,\n",
            "{'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'x_pos_screen': 40, 'y_pos': 79},\n",
            "(240, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "# env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", render_mode='human')\n",
        "env = gym.make(\"SuperMarioBros-1-1-v0\")\n",
        "#Limiting action space to only walk right and jump right\n",
        "#Because of computational limit\n",
        "\n",
        "env = JoypadSpace(env, [['right'], ['right','A']])\n",
        "\n",
        "#Initialize env\n",
        "\n",
        "env.reset()\n",
        "next_state, reward, done, info = env.step(action=0)\n",
        "print(f'{reward},\\n{done},\\n{info},\\n{next_state.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb05fbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deb05fbb",
        "outputId": "343e0916-60fa-4c4b-a439-ddc5edd8c721"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "next_state.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"SuperMarioBros-1-1-v0\")\n",
        "done = True\n",
        "for step in range(5000):\n",
        "    if done:\n",
        "        state = env.reset()\n",
        "    state, reward, done, info = env.step(env.action_space.sample())\n",
        "    env.render()\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "ldNhD6Wy-hHd"
      },
      "id": "ldNhD6Wy-hHd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SkipFrame** is a customized wrapper that comes from gym.wrapper and also impliments step() method. We can skip n-intermediate frames without losing a lot of information because the differences between consecutive frames are not required. Rewards accrued over each skipped frame are combined in the n-th frame."
      ],
      "metadata": {
        "id": "EbtdZrX31W10"
      },
      "id": "EbtdZrX31W10"
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipFrame(gym.Wrapper):\n",
        "  def __init__(self, env, skipframes):\n",
        "    super().__init__(env)\n",
        "    self._frames = skipframes\n",
        "\n",
        "  def step(self, action):\n",
        "    total_reward = 0.0\n",
        "    finish = False\n",
        "    for i in range(self._frames):\n",
        "      #Calculate the reward abd repeat the same action\n",
        "      obs, reward, finish, info = self.env.step(action)\n",
        "      total_reward += reward\n",
        "      if finish:\n",
        "        break\n",
        "    \n",
        "    return obs, total_reward, finish, info"
      ],
      "metadata": {
        "id": "suMPQWnTFR0r"
      },
      "id": "suMPQWnTFR0r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GrayScaleObs** is a popular wrapper to convert an RGB image to grayscale, which shrinks the state representation without sacrificing important information. The size of each state is now: [1, 240, 256]"
      ],
      "metadata": {
        "id": "SI_o_3Js2JPO"
      },
      "id": "SI_o_3Js2JPO"
    },
    {
      "cell_type": "code",
      "source": [
        "class GrayScaleObs(gym.ObservationWrapper):\n",
        "  def __init__(self, env):\n",
        "    super().__init__(env)\n",
        "    observation_shape = self.observation_space.shape[:2]\n",
        "    self.observation_space = Box(low = 0, high = 255, shape = observation_shape, dtype = np.uint8)\n",
        "\n",
        "  def observation(self, obs):\n",
        "    obs = self.permute_proentation(obs)\n",
        "    transform = T.Grayscale()\n",
        "    return  transform(obs)\n",
        "\n",
        "  def permute_proentation(self, obs):\n",
        "    obs = np.transpose(obs, (2, 0, 1))\n",
        "    obs = torch.tensor(obs.copy(), dtype=torch.float)\n",
        "    return obs"
      ],
      "metadata": {
        "id": "R9wGD6crx66F"
      },
      "id": "R9wGD6crx66F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResizeObservation** - Each observation is downsampled into a square picture. New size: [1, 84, 84]"
      ],
      "metadata": {
        "id": "hLMSBuOU2gZv"
      },
      "id": "hLMSBuOU2gZv"
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "  def __init__(self, env, shape):\n",
        "    super().__init__(env)\n",
        "    if isinstance(shape, int):\n",
        "      self.shape = (shape, shape)\n",
        "    else:\n",
        "      self.shape = tuple(shape)\n",
        "    \n",
        "    observation_shape = self.shape + self.observation_space.shape[2:]\n",
        "    self.observation_space = Box(low = 0, high = 255, shape = observation_shape, dtype = np.uint8)\n",
        "\n",
        "  def observation(self, obs):\n",
        "    transforms = T.Compose([T.Resize(self.shape), T.Normalize(0, 255)])\n",
        "    obs = transforms(obs).squeeze(0)\n",
        "    return obs"
      ],
      "metadata": {
        "id": "zDgHPrmOzVHZ"
      },
      "id": "zDgHPrmOzVHZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FrameStack** is a wrapper that enables us to condense multiple environmental frames into one observation point for our learning model. By comparing the direction of Mario's movement in the preceding few frames, we can determine whether he was landing or jumping."
      ],
      "metadata": {
        "id": "jW9yrr_q2v80"
      },
      "id": "jW9yrr_q2v80"
    },
    {
      "cell_type": "code",
      "source": [
        "#Try Applying wrappers to env\n",
        "env = SkipFrame(env, skipframes = 4)\n",
        "env = GrayScaleObs(env)\n",
        "env = ResizeObservation(env, shape = 84)\n",
        "env = FrameStack(env, num_stack=4)"
      ],
      "metadata": {
        "id": "x5BkH6K70Y7m"
      },
      "id": "x5BkH6K70Y7m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mario Agent\n",
        "\n"
      ],
      "metadata": {
        "id": "6YUNlEQ83TRF"
      },
      "id": "6YUNlEQ83TRF"
    },
    {
      "cell_type": "code",
      "source": [
        "class Mario:\n",
        "  def __init__():\n",
        "    pass\n",
        "  \n",
        "  def act(self, state):\n",
        "    #Given a state, return an action\n",
        "    pass\n",
        "  \n",
        "  def cache(self, experience):\n",
        "    #Add experience ie. actions perfromed on states into cache\n",
        "    pass\n",
        "\n",
        "  def recall(self):\n",
        "    #Sample experiences from cache\n",
        "    pass\n",
        "\n",
        "  def learn(self):\n",
        "    #Update action value (Q) function with a batch of experiences\n",
        "    pass"
      ],
      "metadata": {
        "id": "Adr0LnFX1Qaj"
      },
      "id": "Adr0LnFX1Qaj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mario:\n",
        "  def __init__(self, state_dim, action_dim, save_dir):\n",
        "    self.state_dim = state_dim\n",
        "    self.action_dim = action_dim\n",
        "    self.save_dir = save_dir\n",
        "    self.use_cuda = torch.cuda.is_available()\n",
        "    \n",
        "    self.NN = MarioNN(self.state_dim, self.action_dim).float() #Mario's DMM to predict the optimal action given state\n",
        "    if self.use_cuda:\n",
        "      self.NN= self.NN.to(device='cuda')\n",
        "    \n",
        "    self.memory = deque(maxlen=10000) \n",
        "    self.batch_size = 32\n",
        "    self.exploration_rate = 1\n",
        "    self.exploration_rate_decay = 0.9999998\n",
        "    self.exploration_rate_min = 0.1\n",
        "    self.curr_step = 0\n",
        "    self.save_every = 500000\n",
        "    self.gamma  = .9\n",
        "    self.optimizer = torch.optim.Adam(self.NN.parameters(), lr = .0003)\n",
        "    self.smooth_L1_loss = torch.nn.SmoothL1Loss()\n",
        "    self.exp_before_train = 10000\n",
        "    self.learn_every = 3\n",
        "    self.sync_every = 10000\n",
        "\n",
        "  def act(self, state):\n",
        "    \"\"\"\n",
        "      Input:\n",
        "            state - A single obersarvation of the current state frame (state_dim - dimensions)\n",
        "      Output:\n",
        "            action_index - An index value of the action that Mario will perform\n",
        "    \"\"\"\n",
        "    #EXPLORE\n",
        "    if np.random.rand() < self.exploration_rate:\n",
        "      action_index = np.random.randint(self.action_dim)\n",
        "\n",
        "    #EXPLOIT\n",
        "    else:\n",
        "      state = state.__array__()\n",
        "      if self.use_cuda:\n",
        "        state = torch.tensor(state).cuda()\n",
        "      else:\n",
        "        state = torch.tensor(state)\n",
        "      \n",
        "      state = state.unsqueeze(0)\n",
        "      action_values = self.NN(state, model = 'online')\n",
        "      action_index = torch.argmax(action_values, axis = 1).item()\n",
        "    \n",
        "    self.exploration_rate = max(self.exploration_rate*self.exploration_rate_decay, self.exploration_rate_min)\n",
        "    self.curr_step += 1\n",
        "\n",
        "    return action_index\n",
        "\n",
        "  def cache(self, state, next_state, action, reward, finish):\n",
        "    state = state.__array__()\n",
        "    next_state = next_state.__array__()\n",
        "\n",
        "    if self.use_cuda:\n",
        "      state = torch.tensor(state).cuda()\n",
        "      next_state = torch.tensor(next_state).cuda()\n",
        "      action = torch.tensor([action]).cuda()\n",
        "      reward = torch.tensor([reward]).cuda()\n",
        "      finish = torch.tensor([finish]).cuda()\n",
        "\n",
        "    else:\n",
        "      state = torch.tensor(state)\n",
        "      next_state = torch.tensor(next_state)\n",
        "      action = torch.tensor([action])\n",
        "      reward = torch.tensor([reward])\n",
        "      finish = torch.tensor([finish])\n",
        "    \n",
        "    self.memory.append((state, next_state, action, reward, finish))\n",
        "  \n",
        "  def recall(self):\n",
        "    batch = random.sample(self.memory, self.batch_size)\n",
        "    state, next_state, action, reward, finish = map(torch.stack, zip(*batch))\n",
        "\n",
        "    return state, next_state, action.squeeze(), reward.squeeze(), finish.squeeze()\n",
        "  \n",
        "  # Q determines optimal state-action value\n",
        "  def td_estimate(self, state, action):\n",
        "    current_Q = self.NN(state, model = 'online')[np.arange(0, self.batch_size), action]\n",
        "    # online(state, action)\n",
        "    return current_Q\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def td_target(self, reward, next_state, finish):\n",
        "    next_state_Q = self.NN(next_state, model = 'online')\n",
        "    best_action = torch.argmax(next_state_Q, axis = 1)\n",
        "    next_Q = self.NN(next_state, model = 'target')[np.arange(0, self.batch_size), best_action]\n",
        "\n",
        "    return (reward + (1 - finish.float()) * self.gamma * next_Q).float()\n",
        "\n",
        "  def update_Q(self, td_estimate, td_target):\n",
        "    loss = self.smooth_L1_loss(td_estimate, td_target)\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    return loss.item()\n",
        "  \n",
        "  def sync_Q(self):\n",
        "    self.NN.target_model.load_state_dict(self.NN.model.state_dict())\n",
        "\n",
        "  def save_checkpoint(self):\n",
        "    path = (self.save_dir / f'mario_NN_{int(self.curr_step // self.save_every)}.chkpt')\n",
        "\n",
        "    torch.save(dict(model = self.NN.state_dict(), exploration_rate = self.exploration_rate), path)\n",
        "\n",
        "    print(f'Mario NN saved to {path} at step {self.curr_step}')\n",
        "\n",
        "  def learn(self):\n",
        "    if self.curr_step % self.sync_every == 0:\n",
        "      self.sync_Q()\n",
        "\n",
        "    if self.curr_step % self.save_every == 0:\n",
        "      self.save_checkpoint()\n",
        "\n",
        "    if self.curr_step < self.exp_before_train:\n",
        "      return None, None\n",
        "\n",
        "    if self.curr_step % self.learn_every != 0:\n",
        "      return None, None\n",
        "\n",
        "    # Get Sample from Cache\n",
        "    state, next_state, action, reward, finish = self.recall()\n",
        "\n",
        "    td_est = self.td_estimate(state, action)\n",
        "\n",
        "    td_tgt = self.td_target(reward, next_state, finish)\n",
        "\n",
        "    # calculate loss, backpropagate\n",
        "    loss = self.update_Q(td_est, td_tgt)\n",
        "\n",
        "    return (td_est.mean().item(), loss)"
      ],
      "metadata": {
        "id": "1knHIYuT4fpk"
      },
      "id": "1knHIYuT4fpk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MarioNN(nn.Module):\n",
        "  \"\"\"\n",
        "      CCN Structure:\n",
        "  input -> (conv2d + ReLU) x 3 -> Flatten -> (fully connected dense + ReLU) x 2 -> output\n",
        "  \"\"\"\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "    \n",
        "    channel, height, width = input_dim\n",
        "    if height != 84 or width != 84:\n",
        "      raise ValueError(f'Expected input height and width: 84, got: height {height}, width {width}')\n",
        "    \n",
        "    self.model = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = channel, out_channels = 32, kernel_size = 8, stride = 4), # (20 X 20 X 32)\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 4, stride = 2), # (8 X 8 X 64)\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1), # (7 X 7 X 64)\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(), # (7 X 7 X 64 = 3136)\n",
        "\n",
        "        #[(height ‚àí filter_size + 1) / ùë†tride] + 1\n",
        "\n",
        "        nn.Linear(in_features = 3136, out_features = 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features = 512, out_features = output_dim)\n",
        "    )\n",
        "\n",
        "    self.target_model = copy.deepcopy(self.model)\n",
        "\n",
        "    # Q_target model parameters needs to be frozen by disabling the gredients\n",
        "    for w in self.target_model.parameters():\n",
        "      w.requires_grad = False\n",
        "\n",
        "  def forward(self, input, model):\n",
        "    if model == 'online':\n",
        "      return self.model(input)\n",
        "    elif model == 'target':\n",
        "      return self.target_model(input)"
      ],
      "metadata": {
        "id": "jb6kCUoP-SyQ"
      },
      "id": "jb6kCUoP-SyQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "  print(f'Using CUDA: {use_cuda}\\n')\n",
        "else:\n",
        "  print('Using CPU\\n')\n",
        "\n",
        "episodes = 10000\n",
        "\n",
        "for e in tqdm(range(episodes), desc='Episodes'):\n",
        "  state = env.reset() # return initial state\n",
        "  \n",
        "  while True:\n",
        "\n",
        "    # env.render()\n",
        "\n",
        "    action = mario_agent.act(state) # return action (index) on given state\n",
        "\n",
        "    next_state, reward, finish, info = env.step(action) # perform the action on the environment\n",
        "\n",
        "    mario_agent.cache(state, next_state, action, reward, finish) # store the state-action-reward cache\n",
        "\n",
        "    Q, loss = mario_agent.learn() # Learn\n",
        "\n",
        "    state = next_state # update the state\n",
        "\n",
        "    if finish or info['flag_get']:\n",
        "      break\n",
        "  if e % 500 == 0 and e != 0:\n",
        "    mario_agent.save_dir= Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
        "    mario_agent.save_dir.mkdir(parents=True)\n",
        "    mario_agent.save_checkpoint()\n",
        "  # env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5cPwxaVEq0_",
        "outputId": "ddcb46a8-5405-4eef-c006-343a3b1c8c71"
      },
      "id": "k5cPwxaVEq0_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA: True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpisodes:   0%|                                                                              | 0/10000 [00:00<?, ?it/s]C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n",
            "Episodes:   5%|‚ñà‚ñà‚ñà‚ñé                                                              | 501/10000 [30:31<9:57:30,  3.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T01-07-29\\mario_NN_0.chkpt at step 97922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 1001/10000 [57:46<6:55:56,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T01-34-44\\mario_NN_0.chkpt at step 194440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 1501/10000 [1:24:38<9:22:21,  3.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T02-01-36\\mario_NN_0.chkpt at step 291404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 2001/10000 [1:52:43<8:21:20,  3.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T02-29-40\\mario_NN_0.chkpt at step 386346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 2501/10000 [2:20:05<5:40:35,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T02-57-03\\mario_NN_0.chkpt at step 482539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                              | 2596/10000 [2:25:02<7:30:33,  3.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T02-57-03\\mario_NN_1.chkpt at step 500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                            | 3001/10000 [2:47:49<7:07:16,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T03-24-47\\mario_NN_1.chkpt at step 579861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                         | 3501/10000 [3:15:49<7:14:12,  4.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T03-52-46\\mario_NN_1.chkpt at step 678064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                     | 4001/10000 [3:45:18<5:08:10,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T04-22-16\\mario_NN_1.chkpt at step 781354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 4501/10000 [4:12:48<5:10:32,  3.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T04-49-46\\mario_NN_1.chkpt at step 877344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 5001/10000 [4:41:56<5:05:57,  3.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T05-18-54\\mario_NN_1.chkpt at step 978495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 5091/10000 [4:47:58<4:41:31,  3.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T05-18-54\\mario_NN_2.chkpt at step 1000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 5501/10000 [5:12:04<3:09:23,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T05-49-02\\mario_NN_2.chkpt at step 1084018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 6001/10000 [5:39:50<2:46:55,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T06-16-48\\mario_NN_2.chkpt at step 1181233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 6501/10000 [6:06:55<3:49:26,  3.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T06-43-52\\mario_NN_2.chkpt at step 1276718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 7001/10000 [6:34:20<4:31:32,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T07-11-18\\mario_NN_2.chkpt at step 1373018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 7501/10000 [7:04:44<2:18:05,  3.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T07-41-42\\mario_NN_2.chkpt at step 1478684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 7589/10000 [7:13:00<2:25:23,  3.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T07-41-42\\mario_NN_3.chkpt at step 1500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 8001/10000 [7:37:23<1:46:08,  3.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T08-14-21\\mario_NN_3.chkpt at step 1581883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 8501/10000 [8:05:57<1:36:26,  3.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T08-42-53\\mario_NN_3.chkpt at step 1681002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 9001/10000 [8:35:47<1:37:50,  5.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T09-12-45\\mario_NN_3.chkpt at step 1784245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 9501/10000 [9:06:55<28:39,  3.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T09-43-53\\mario_NN_3.chkpt at step 1891878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 9984/10000 [9:37:53<02:00,  7.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T09-43-53\\mario_NN_4.chkpt at step 2000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episodes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [9:39:18<00:00,  3.48s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KnNqO23XrwZm"
      },
      "id": "KnNqO23XrwZm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mario_agent.save_dir= Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
        "mario_agent.save_dir.mkdir(parents=True)\n",
        "mario_agent.save_checkpoint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MM3SgF0RMJo",
        "outputId": "69ca3a7b-9709-46ba-98d9-b4336dff0e62"
      },
      "id": "-MM3SgF0RMJo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario NN saved to checkpoints\\2022-10-05T11-06-38\\mario_NN_4.chkpt at step 2006293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "8a5AFsnpPZae"
      },
      "id": "8a5AFsnpPZae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the model"
      ],
      "metadata": {
        "id": "j-f7TGFe4Ffe"
      },
      "id": "j-f7TGFe4Ffe"
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"SuperMarioBros-1-1-v0\")\n",
        "\n",
        "# #Limiting action space to only walk right and jump right\n",
        "# #Because of computational limit\n",
        "env = JoypadSpace(env, [['right'], ['right','A']])\n",
        "\n",
        "#Try Applying wrappers to env\n",
        "env = SkipFrame(env, skipframes = 4)\n",
        "env = GrayScaleObs(env)\n",
        "env = ResizeObservation(env, shape = 84)\n",
        "env = FrameStack(env, num_stack=4)\n",
        "\n",
        "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
        "save_dir.mkdir(parents=True)\n",
        "\n",
        "mario_agent = Mario(state_dim = (4, 84, 84), action_dim = env.action_space.n, save_dir = save_dir)"
      ],
      "metadata": {
        "id": "EwzGSC__goIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1c9e8a-8d6e-4c97-fce1-217961b51c37"
      },
      "id": "EwzGSC__goIe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\gym\\envs\\registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\gym\\core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_model_path = \"F:/checkpoints/2022-10-05T11-06-38/mario_NN_4.chkpt\"\n",
        "\n",
        "mario_agent.NN.load_state_dict(torch.load(load_model_path)['model'])\n",
        "mario_agent.exploration_rate = torch.load(load_model_path)['exploration_rate']\n",
        "# mario_agent.exploration_rate = 0    #Setting exploration rate to 0, so agent can use optimal state value action"
      ],
      "metadata": {
        "id": "vuu-oEoKgoKc"
      },
      "id": "vuu-oEoKgoKc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mario_agent.NN.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEyLNzfv8dfK",
        "outputId": "8df70d0e-e300-4be2-c2f3-e5eb5217ba6b"
      },
      "id": "MEyLNzfv8dfK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MarioNN(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): Flatten(start_dim=1, end_dim=-1)\n",
              "    (7): Linear(in_features=3136, out_features=512, bias=True)\n",
              "    (8): ReLU()\n",
              "    (9): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              "  (target_model): Sequential(\n",
              "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): Flatten(start_dim=1, end_dim=-1)\n",
              "    (7): Linear(in_features=3136, out_features=512, bias=True)\n",
              "    (8): ReLU()\n",
              "    (9): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epi = 10\n",
        "for i in range(epi):\n",
        "  state = env.reset() # return initial state\n",
        "  while True:\n",
        "\n",
        "    env.render()\n",
        "\n",
        "    action = mario_agent.act(state) # return action (index) on given state\n",
        "\n",
        "    next_state, reward, finish, info = env.step(action) # perform the action on the environment\n",
        "\n",
        "    state = next_state # update the state\n",
        "\n",
        "    if finish or info['flag_get']:\n",
        "      break"
      ],
      "metadata": {
        "id": "gz1ZJ75GgoGc"
      },
      "id": "gz1ZJ75GgoGc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "CJ9Y8UEs6KlV"
      },
      "id": "CJ9Y8UEs6KlV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mario_agent.exploration_rate = 0.1"
      ],
      "metadata": {
        "id": "E2JyPMRr6tA6"
      },
      "id": "E2JyPMRr6tA6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vbT-OiZ3A3NY"
      },
      "id": "vbT-OiZ3A3NY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}